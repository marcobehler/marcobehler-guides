= Kubernetes for Lazy Developers
Marco Behler
2023-11-16
:page-layout: layout-guides
:page-image: "TODO"
:page-description: TODO
:page-published: false
:page-tags: ["kuberntes"]
:page-commento_id: /guides/kubernetes-for-lazy-developer

(*Editorâ€™s note*: At ~n words, you probably don't want to try reading this on a mobile device. Bookmark it and come back later.)

== Introduction

If you're a developer who has either never used Kubernetes before or wants to brush up on Kubernetes knowledge so that your DevOps colleagues will be [line-through]#scared# positively surprised, this guide is for you.

*Quick Question*: Why is Kubernetes abbreviated to K8s?

*Answer*: It will magically reveal itself at the end of this guide, but only after you having fully read it. So, let's not waste any more time.

=== How did we get here?

Many developers I've met throughout my career, didn't necessarily care about the "now that I've written the code, it also needs to be run somewhere"-part of application development.

What does running an application actually mean? It depends a bit on your programming language ecosystem, but in terms of Java and modern web applications, you literally compile all your source in one, single, executable .jar file, that you can run with a simple command.

[source,java]
----
java -jar myNewAIStartup.jar
----

Yes, there is additionally very likely an `_application.properties_` file involved, to set e.g. production database credentials, but the command above is literally it: If you're deploying your application on bare metal, in a VM, in a Docker container, with or without Kubernetes, or your Java-powered toaster (ok, I made that one up).

=== Running just one command can't be it. Where is the catch?

Much has been written online about the issues that can arise when deploying your application:

* What if there are version incompatibilities between my DEV environment and my PRD environment?
* What if certain, needed OS packages are missing?
* What if we're not going to deploy our application to a cloud service anymore, but a submarine?

Interestingly, your mileage with these problems will vary _a lot_ depending on what programming language ecosystem you're using, a topic that is often ignored in online discussions.

With pure Java web-applications, the issues mentioned above (apart from the submarine, of course), are essentially non-issues. You install a JDK, which is https://www.marcobehler.com/guides/a-guide-to-java-versions-and-features[insanely backwards compatible], on a server/vm/container, and run `_java -jar_`.

With PHP, Python, or Ruby the picture looks different and you could/can easily run into version incompatibilities across your dev, staging or prod environments. Hence, people yearned for a solution to rid them of these pains: Containers. (*Side-Note)

// TODO Site-Note : all these concerns aren't new....applicatikon servers etc.......schnittstellen

=== Hail to the Docker!

Chances are high that you already know what Docker is and how to work with it. (If not and you want to see a Docker specific guide, please post a comment down below! More demand -> Faster publication). The short summary is:

* You build your deployable, e.g. the `_jar_` file.
* You build a new Docker image, which contains your `_jar_` file.
* The Docker Image also contains _all_ additional software and configuration options needed to run.

-> You will now deploy your Docker image (and run it as a Docker container), instead of your .jar file. The beauty is: As long as you have Docker installed on the target machine you can run any Docker image you want (and you have Kernel compatibility between your host OS and the Docker container ).

[source,console]
----
docker run --name my-new-ai-startup -p 80:8080 -d mynewaistartup
----

This will start a Docker container on basis of the `_mynewaistartup_` Docker image. That image will, among other things, contain your e.g. -jar file, a web application which runs on port 8080, as well as instructions on how to run it. Hint: These instructions are `_java -jar mynewaistartup.jar_`.

=== What do we do with these Docker images?

You or your CI/CD server managed to bake your application into a Docker image. But how does that Docker image eventually end up on your target deployment server?

You'll need to push your Docker image to a Docker registry, be that https://hub.docker.com/_/registry[dockerhub], https://aws.amazon.com/ecr/[Amazon ECR] or any of the other gazillion self-hosted container image registries, like https://docs.gitlab.com/ee/user/packages/container_registry/[Gitlab's], for example.

Once your image made it to said registry, you can https://docs.docker.com/engine/reference/commandline/login/[login] to that registry on your targetserver.

[source,console]
----
docker login mysupersecret.registry.com
----

And once you are logged in to your registry, your `_docker run_` will be able to find your custom images.

[source,console]
----
docker run --name my-new-ai-startup -p 80:8080 -d mynewaistartup

//....

SUCCESS!
----

=== Docker Compose: Running more than one container simultaneously

What if your application consists of more than just a single Docker container, say, because you need to run https://www.marcobehler.com/guides/java-microservices-a-practical-guide[98354 microservices]?

https://docs.docker.com/compose/[Docker Compose] to the rescue. You'll define all your services and the dependencies between them (run this one or the other one first) in a good, old, YAML file, a `_compose.yaml_`. Here's an example of such a file, defining two services, a web service and a redis service.

[source,yaml]
----
services:
  web:
    build: .
    ports:
      - "8000:5000"
    volumes:
      - .:/code
      - logvolume01:/var/log
    depends_on:
      - redis
  redis:
    image: redis
volumes:
  logvolume01: {}
----

Then you just run `_docker compose up_` and your whole _environment_ (consisting of all your separate services) will be started.

While `_Docker Compose_` might be mainly known for quickly spinning up development or testing environments, it actually works really well for single host deployments as well.
If your application...

* doesn't have any specific high-availability requirements
* you don't mind some manual work (ssh login, docker compose up/down) or using a complementary tool like https://www.ansible.com/[Ansible]
* or you simply don't want to spend enormous amounts of [line-through]#money# investments on a DevOps team

...using Docker Compose for production deployments will go a long way.

=== What do I need Kubernetes for, then?

Things get interesting if you want to start running hundreds, thousands (or a multiple of that) containers, if you don't care or don't want to know on what specific underlying hardware/box your containers will be running on, yet still want to be able to sensibly manage all of this. Kubernetes, to the rescue!

Let's do a quick Kubernetes Concept 101.

TODO GRAPH UML control pane workload..

=== Kubernetes 102: (Worker) Nodes

Your software (or _workload_ in Kubernetes terms) has to run somewhere, be it a virtual or physical machine. Kubernetes call this somewhere `_Nodes_`.

Furthermore, Kubernetes deploys and runs containers: Hello, Docker, my old friend!

Actually, this is not 100% right. In Kubernete's terms, you deploy `_Pods_`, with a pod consisting of one or more containers.

Alright, we got `_pods_` running on `_nodes_`, but who controls those nodes and how and where do you decide what to run on these `_nodes_`?

=== Kubernetes 101: Control Pane

Meet the `_Control Plane_` For simplicity's sake, let's just think of it as _one_ component that controls your node (as opposed to the https://kubernetes.io/docs/concepts/overview/components/[roughly 947 components] it consists of):

* Let's [line-through]#run# _schedule_ your application, i.e. let's put a pod on a node.
* Are your pods all in the desired state, e.g. responsive or does one of them need to be restarted?
* Every engineer's dream: We need to finally scale (yay!), let's quickly spin up 5 more pods!

=== Kubernetes 101: Clusters & Clouds

Take your nodes and your control pane, and you have a cluster.

Take multiple clusters e.g. to separate dev, test & production environments or maybe teams/projects/application types.

The gold standard ('tm), run multiple clusters across multiple private and/or public cloud platforms: Multi-Cloud Kubernetes!

=== Kubernetes 101: Addons

Web UI...Amazon dashboard...Goolg eCloud Console...


=== Is that it?

this is a quick summary for developers...the truth is...enormous complexity....books on oreilly.......more pages than you can imagine to read


=== How does Kubernetes do all this? YAML!

YAML, YAML, YAML...have a deployment...tell Kubernetes: Go.

=== Why do I as a developer need to know this stuff?

If you have been reading along so far,

== How can I apply this YAML file?

kubectl...

=== Kubectl primer

What is kubectl?

what can kubectl do? apply ? ssh? other stuff?

=== Meet kubeconfig file

kubectl works against a clste.r.....namepsaces..

=== Self-Healing: Lie

self healing: systemd oder supervisord

pods
wie
run containers.....healthchecks...self healing....what does that even mean? ubuntu/upstart since the break of dawn: restart hanging processes

=== What else can Kubernetes do for me? Secrets Management

https://docs.spring.io/spring-cloud-kubernetes/docs/current/reference/html/

=== Don't these YAML files become a mess?

Kustomize / Helm Charts + IDE support



IntelliJ IDEA support

https://www.jetbrains.com/help/idea/kubernetes.html  (IntelliJ IDEA Ultimate)

[link video]

=== what are helm charts...

=== what is kustomize?

=== What is Terraform?

=== DO I really need all of this?

cgroups....resources....limitation......real life -> 0,5 CPUS.....in development needing the latest macbook pro 64 gig

book reference....100s of applications ok...but what about 100thousands.....missing reference (anyone?)

Comparison with ansible.....puppet?

application servers vs kubernetes...

=== Framework Support

spring boot builds directly into docker image.....optimized .....

=== How does Kubernetes influence my local development?

=== How do I do local development with Kubernetes?

twitter poll

For Development...Docker compose.....

docker-compose files...and K8s manifest files...

clulster & skaffold

minikube....

testcontainers...

===  online hype stories && what ifs?????

strive a career in sales and marketing if you can plausibly explain where 5x the traffic will come from tomorrow....

online hype stories vs reality

blog post from jason cohen on

https://longform.asmartbear.com/exponential-growth/

=== moving complexity

reference kubernetes book...2016 devops...study...would like to have a closer look

100000 of books for Kubernetes...100s of pages to set up just networking

Answered: K8s as an abbreviation results from counting the eight letters between the "K" and the "s". https://kubernetes.io/docs/concepts/overview/#:~:text=rapidly%20growing%20ecosystem.-,Kubernetes%20services%2C%20support%2C%20and%20tools%20are%20widely%20available.,the%20Kubernetes%20project%20in%202014[(source)].

Enough with random, boring facts no one will remember, let's start at the very beginning.


=== Fin

small workloads, vs . google sized workloads....while default seems to be k8, do you really NEED this stuff??

== Acknowledgments

Yet to come. Ssend in a PR btw if you don't like something




=== TODO




nenn mir EIN docker image das du OHNE ZU WISSEN WAS ES TUT einfach wo deployen kannst
du musst auf dockerhub die environment variables lesen
du mussst wissen welche volumes und shit du bereitstellen musst
es ist also nicht "doppelklick app.exe"

rl problem: too little reosurces, killing health-checks, oom, architects, etc.
